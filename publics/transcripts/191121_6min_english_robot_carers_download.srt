1
00:00:00,000 --> 00:00:03,120
This is a download from BBC Learning English.

2
00:00:03,120 --> 00:00:05,679
To find out more, visit our website.

3
00:00:13,519 --> 00:00:18,160
Hello, this is 6 Minute English, I'm Rob, and joining me to do this is Sam.

4
00:00:18,160 --> 00:00:19,039
Hello.

5
00:00:19,039 --> 00:00:22,600
In this program, we're talking about robots.

6
00:00:22,600 --> 00:00:24,719
Robots can perform many tasks,

7
00:00:24,719 --> 00:00:29,199
but they're now being introduced in social care to operators' carers

8
00:00:29,199 --> 00:00:31,519
to look after the sick and elderly.

9
00:00:31,519 --> 00:00:35,280
We'll be discussing the positive and negative issues around this,

10
00:00:35,280 --> 00:00:39,039
but first, let's set you a question to answer, Sam. Are you ready for this?

11
00:00:39,039 --> 00:00:40,320
Fire away.

12
00:00:40,320 --> 00:00:44,399
Do you know in which year was the first commercial robot built?

13
00:00:44,399 --> 00:00:47,359
Was it in a 1944,

14
00:00:47,359 --> 00:00:52,000
B 1954, or C 1964?

15
00:00:52,000 --> 00:00:57,200
They're not brand new inventions, so I'll go for 1954.

16
00:00:57,200 --> 00:01:02,000
OK, well, I'll tell you if you're right or wrong at the end of the program.

17
00:01:02,000 --> 00:01:05,200
So let's talk more about robots, and specifically,

18
00:01:05,200 --> 00:01:07,840
ones that are designed to care for people.

19
00:01:07,840 --> 00:01:13,680
Traditionally, it's humans working as nurses or carers who take care of elderly people.

20
00:01:13,680 --> 00:01:17,600
Those people who are too old or too unwell to look after themselves.

21
00:01:17,600 --> 00:01:22,159
But finding enough carers to look after people is a problem.

22
00:01:22,159 --> 00:01:26,480
There are more people needing care than there are people who can help.

23
00:01:26,560 --> 00:01:31,840
And recently in the UK, the government announced a Â£34 million fund

24
00:01:31,840 --> 00:01:36,000
to help develop robots to look after us in our later years.

25
00:01:36,640 --> 00:01:39,120
Well, robot carers are being developed,

26
00:01:39,120 --> 00:01:44,000
but can they really learn enough empathy to take care of the elderly and unwell?

27
00:01:44,000 --> 00:01:47,760
Empathy is the ability to understand how someone feels

28
00:01:47,760 --> 00:01:51,520
by imagining what it would be like to be in that person's situation.

29
00:01:52,239 --> 00:01:56,879
Well, let's hear about one of those new robots now called Peppa.

30
00:01:56,879 --> 00:02:02,159
Abbey Herne Nagath is a research assistant at the University of Bedfordshire.

31
00:02:02,159 --> 00:02:06,079
She spoke to BBC Radio 4's You and Yours programme

32
00:02:06,079 --> 00:02:10,079
and explained how Peppa is first introduced to someone in a care home.

33
00:02:10,719 --> 00:02:14,639
We just bring the robot to their room, and we talk about what Peppa can't do,

34
00:02:14,639 --> 00:02:18,560
which is important, so he can't provide physical assistance in any way.

35
00:02:18,560 --> 00:02:20,960
It does have hands, it can wave.

36
00:02:21,040 --> 00:02:24,960
When you ask for privacy, it does turn around and sort of cover its eyes with its hands,

37
00:02:24,960 --> 00:02:26,159
but that's the most it does.

38
00:02:26,159 --> 00:02:28,480
It doesn't grip anything, it doesn't move anything,

39
00:02:28,480 --> 00:02:32,159
because we're more interested to see how it works as a companion,

40
00:02:32,159 --> 00:02:35,760
having something there to talk to, to converse with, to interact with.

41
00:02:36,319 --> 00:02:40,000
So Abbey described how the robot is introduced to someone.

42
00:02:40,719 --> 00:02:46,319
She was keen to point out that this robot has limitations, things it can't do.

43
00:02:47,039 --> 00:02:52,000
It can wave or turn round when a person needs privacy to be private,

44
00:02:52,000 --> 00:02:54,799
but it can't provide physical assistance.

45
00:02:55,439 --> 00:02:59,680
This means it can't help someone by touching or feeling them.

46
00:02:59,680 --> 00:03:01,759
But that's okay, Abbey says.

47
00:03:01,759 --> 00:03:05,120
This robot is designed to be a companion,

48
00:03:05,120 --> 00:03:07,439
someone who is with you to keep you company,

49
00:03:07,439 --> 00:03:11,039
a friend in other words that you can converse or talk with.

50
00:03:11,039 --> 00:03:15,519
Well, having a companion is a good way to stop people getting lonely,

51
00:03:15,520 --> 00:03:18,159
but surely a human is better for that.

52
00:03:18,800 --> 00:03:22,080
Surely they understand you better than a robot ever can.

53
00:03:22,719 --> 00:03:26,640
Well, innovation means that robots are becoming cleverer all the time.

54
00:03:27,280 --> 00:03:32,080
And as we've mentioned, in the UK alone, there's a growing elderly population

55
00:03:32,080 --> 00:03:35,520
of more than 100,000 care assistant vacancies.

56
00:03:35,520 --> 00:03:36,719
Who's going to do all the work?

57
00:03:37,600 --> 00:03:40,320
I think we should hear from Dr. Sarah Wooden,

58
00:03:40,320 --> 00:03:44,320
a health researcher in independent living from Leeds University,

59
00:03:44,319 --> 00:03:47,919
who also spoke to the BBC's UN Joer's programme.

60
00:03:48,560 --> 00:03:53,199
She seems more realistic about the introduction of robot carers.

61
00:03:54,000 --> 00:03:58,799
I think there are problems if we consider robots as replacement for people.

62
00:03:58,799 --> 00:04:00,959
We know that money is tight.

63
00:04:01,599 --> 00:04:05,519
If robots become mass produced, they could be large institutions

64
00:04:05,519 --> 00:04:10,879
where people might be housed and abandoned to robots.

65
00:04:10,879 --> 00:04:16,240
I do think questions of ethics need to come into the growth and jobs agenda as well,

66
00:04:16,240 --> 00:04:18,560
because sometimes they're treated very separately.

67
00:04:18,560 --> 00:04:22,319
OK, so Sarah Wooden suggests that when money is tight,

68
00:04:22,319 --> 00:04:24,079
meaning there's only just enough,

69
00:04:24,079 --> 00:04:27,680
making robots in large quantities or mass produced

70
00:04:27,680 --> 00:04:30,639
might be a cheaper option than using humans.

71
00:04:30,639 --> 00:04:33,600
And she says people might be abandoned to robots.

72
00:04:33,600 --> 00:04:39,040
Yes, abandoned means left alone in a place, usually forever.

73
00:04:39,600 --> 00:04:44,080
So she says it might be possible that someone ends up being forgotten

74
00:04:44,080 --> 00:04:46,560
and only having a robot to care for them.

75
00:04:47,200 --> 00:04:49,760
So is this right, ethically?

76
00:04:49,760 --> 00:04:51,920
Yes, well, she mentions ethics.

77
00:04:51,920 --> 00:04:53,920
That's what is morally right,

78
00:04:53,920 --> 00:04:57,360
and that needs to be considered as part of the jobs agenda.

79
00:04:57,360 --> 00:05:00,720
So we shouldn't just consider what job vacancies need filling,

80
00:05:00,720 --> 00:05:02,560
but who and how it should be done.

81
00:05:03,200 --> 00:05:04,640
And earlier, I asked you, Sam,

82
00:05:04,640 --> 00:05:08,320
did you know in which year was the first commercial robot built?

83
00:05:08,399 --> 00:05:11,120
When you said, I said 1954.

84
00:05:11,120 --> 00:05:14,560
Well, you didn't need a robot to help you there because you are right.

85
00:05:14,560 --> 00:05:15,759
Yay. Well done.

86
00:05:16,480 --> 00:05:19,199
Now let's do something a robot can't do yet,

87
00:05:19,199 --> 00:05:22,319
and that's recap of the vocabulary we've highlighted today.

88
00:05:22,319 --> 00:05:23,920
Starting with empathy.

89
00:05:24,560 --> 00:05:28,079
Empathy is the ability to understand how someone feels

90
00:05:28,079 --> 00:05:32,240
by imagining what it would be like to be in that person's situation.

91
00:05:32,240 --> 00:05:36,639
Physical assistance describes helping someone by touching them.

92
00:05:36,639 --> 00:05:38,560
We also mentioned a companion.

93
00:05:38,560 --> 00:05:41,360
That's someone who is with you and keeps you company.

94
00:05:41,360 --> 00:05:43,439
Our next word was tight.

95
00:05:43,439 --> 00:05:46,159
In the context of money, when money is tight,

96
00:05:46,159 --> 00:05:48,079
it means there's not enough.

97
00:05:48,079 --> 00:05:51,439
Abandoned means left alone in a place, usually forever.

98
00:05:51,439 --> 00:05:54,240
And finally, we discuss the word ethics.

99
00:05:54,240 --> 00:05:58,000
We hear a lot about business ethics or medical ethics,

100
00:05:58,000 --> 00:06:01,279
and it means the study of what is morally right.

101
00:06:01,279 --> 00:06:02,879
Okay, thank you, Sam.

102
00:06:03,279 --> 00:06:05,439
Well, we've managed to get through six minutes English

103
00:06:05,519 --> 00:06:07,040
without the aid of a robot.

104
00:06:07,759 --> 00:06:10,000
That's all for now, but please join us again soon.

105
00:06:10,000 --> 00:06:11,519
Goodbye. Bye-bye, everyone.

106
00:06:12,719 --> 00:06:19,680
Six-nate English from BBC Learning English.

