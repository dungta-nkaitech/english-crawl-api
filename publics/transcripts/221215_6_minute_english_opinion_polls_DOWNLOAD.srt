1
00:00:00,000 --> 00:00:03,120
This is a download from BBC Learning English.

2
00:00:03,120 --> 00:00:05,679
To find out more, visit our website.

3
00:00:13,519 --> 00:00:17,760
Hello, this is 6 Minute English from BBC Learning English. I'm Neil.

4
00:00:17,760 --> 00:00:18,960
And I'm Sam.

5
00:00:18,960 --> 00:00:24,080
Predicting the future is not easy, but that's exactly the job of opinion pollsters.

6
00:00:24,080 --> 00:00:29,679
Researchers who ask people questions to discover what they think about certain topics.

7
00:00:29,679 --> 00:00:34,159
Often their aim is predicting which political party will win in an election,

8
00:00:34,159 --> 00:00:37,439
by asking members of the public how they intend to vote.

9
00:00:37,439 --> 00:00:41,759
But predicting the future is never 100% accurate,

10
00:00:41,759 --> 00:00:45,200
and opinion polls don't always get it right.

11
00:00:45,200 --> 00:00:50,960
In 2016, few pollsters predicted a victory for Donald Trump over Hillary Clinton

12
00:00:50,960 --> 00:00:53,359
in the US presidential election.

13
00:00:53,359 --> 00:00:57,519
And in the 2020 US elections, most polls predicted Trump

14
00:00:57,600 --> 00:01:01,920
would lose to Joe Biden by a much larger amount than he actually did.

15
00:01:02,560 --> 00:01:08,640
These mistakes, sometimes called misfires, when things do not work in the way intended,

16
00:01:08,640 --> 00:01:11,680
have damaged the reputation of opinion pollsters.

17
00:01:11,680 --> 00:01:15,920
In this programme, we'll be taking a look into the opinion polling industry.

18
00:01:15,920 --> 00:01:19,280
And of course, learning some useful vocabulary as well.

19
00:01:19,280 --> 00:01:21,760
But first, I have a question for you, Sam.

20
00:01:21,760 --> 00:01:25,359
And it's about another time when the opinion polls got it wrong.

21
00:01:26,239 --> 00:01:30,640
Few pollsters predicted that Britain would vote to leave the European Union

22
00:01:30,640 --> 00:01:35,039
in the 2016 Brexit referendum, which in the end, it did.

23
00:01:35,680 --> 00:01:41,519
But what was the final split between those who voted to leave and those who wanted to remain?

24
00:01:41,519 --> 00:01:45,359
Was it A, 51 leave to 49 remain?

25
00:01:45,359 --> 00:01:48,719
B, 52 leave to 48 remain?

26
00:01:48,719 --> 00:01:52,159
Or C, 52 remain to 48 leave?

27
00:01:52,159 --> 00:01:58,079
I think it was B, 52% voted to leave and 48% to remain.

28
00:01:58,079 --> 00:02:01,200
OK, Sam, I'll reveal the answer at the end of the programme.

29
00:02:01,759 --> 00:02:08,639
One of the biggest polling companies was founded by George Gallup, born in 1901 on a farm in Iowa.

30
00:02:08,639 --> 00:02:10,879
Gallup was a student of journalism.

31
00:02:10,879 --> 00:02:16,159
He wanted to know people's opinion on a range of subjects and came up with a simple idea.

32
00:02:16,719 --> 00:02:18,479
Why not try asking them?

33
00:02:19,280 --> 00:02:23,199
Here's G. Elliott Morris, a data journalist from the Economist,

34
00:02:23,199 --> 00:02:26,719
explaining more to BBC World Service programme, more or less.

35
00:02:27,519 --> 00:02:32,079
And he publishes his dissertation on this, how to measure what people want, basically.

36
00:02:32,079 --> 00:02:38,000
And he gets hired by a much bigger advertising agency in New York called Young and Rubikam.

37
00:02:38,000 --> 00:02:43,679
And they basically give him a blank check to do their research, to figure out how to call people,

38
00:02:43,680 --> 00:02:48,480
how to talk to them, to figure out if they remember or like to certain product,

39
00:02:48,480 --> 00:02:52,640
basically to figure out early methodologies in advertising.

40
00:02:52,640 --> 00:02:58,719
And then by 1931 or so, he's wondering, well, if it works for toothpaste, why not politics?

41
00:02:59,280 --> 00:03:03,439
George Gallup tried to figure out what customers wanted to buy.

42
00:03:03,439 --> 00:03:08,800
If you figure something out, you finally understand it or find a solution to a problem

43
00:03:08,800 --> 00:03:10,480
after thinking about it a lot.

44
00:03:11,280 --> 00:03:17,039
Lacer, he was hired by a New York advertising agency to find out people's opinion of consumer

45
00:03:17,039 --> 00:03:22,560
products like toothpaste and soft drinks. George was given a blank check,

46
00:03:22,560 --> 00:03:26,239
an unlimited amount of money and freedom to do his job.

47
00:03:26,239 --> 00:03:31,280
At this time, polling was focused on consumer preferences, not politics.

48
00:03:31,280 --> 00:03:36,639
But asking people about their political views is a lot more complicated than asking them about

49
00:03:36,639 --> 00:03:43,279
toothpaste. Making accurate election predictions depends on polling a sample group of people

50
00:03:43,279 --> 00:03:49,199
who accurately represent the population as a whole. One of the reasons for Polsters failure to

51
00:03:49,199 --> 00:03:55,439
predict Trump's election in 2016 is that they didn't ask enough white, non-college educated voters.

52
00:03:56,079 --> 00:04:01,279
So polling is a very complex process, one which is never totally reliable,

53
00:04:01,919 --> 00:04:07,039
according to G. Eliot Morris, speaking again here to BBC World Services, more or less.

54
00:04:07,920 --> 00:04:13,360
If people were understanding this process that's generating all these polls,

55
00:04:13,360 --> 00:04:18,319
then they would understand polls as less sort of precise tools. Tools that definitely can't

56
00:04:18,319 --> 00:04:22,240
offer the laser-like predictive accuracy we've come to expect from them,

57
00:04:22,240 --> 00:04:27,519
then the difference between polling's expectations and performance wouldn't be so stark.

58
00:04:28,000 --> 00:04:33,279
Opinion polls can estimate the outcome of an election, but they can't give us laser-like

59
00:04:33,279 --> 00:04:39,279
accuracy. If you describe something as laser-like, you mean it's very accurate and focused,

60
00:04:39,279 --> 00:04:44,240
like a laser. If people understand how hard it is to predict the future,

61
00:04:44,240 --> 00:04:48,319
they might be more realistic about how accurate opinion polls can be.

62
00:04:49,120 --> 00:04:54,319
Then differences between a prediction and the final result wouldn't be so stark.

63
00:04:55,120 --> 00:04:57,759
Obvious and easily visible or harsh.

64
00:04:58,399 --> 00:05:03,439
Predicting the future is difficult, otherwise everyone would be a lottery winner by now.

65
00:05:04,159 --> 00:05:09,360
Maybe it's not opinion polls that are broken, but our desire to know the future that's the problem.

66
00:05:10,159 --> 00:05:14,399
Okay, it's time to reveal the answer to my question about the Brexit referendum.

67
00:05:15,199 --> 00:05:20,800
I said the final result was 52% for leave and 48% for remain.

68
00:05:20,879 --> 00:05:26,560
Which was the correct answer and another example of an opinion poll misfire,

69
00:05:26,560 --> 00:05:30,079
a situation where something does not work as intended.

70
00:05:30,800 --> 00:05:35,840
Okay, let's recap the rest of the vocabulary from this program about opinion pollsters.

71
00:05:35,840 --> 00:05:40,639
People who conduct polls asking the public their opinion on particular subjects,

72
00:05:40,639 --> 00:05:45,920
especially politics. If you figure something out, you finally understand it,

73
00:05:46,000 --> 00:05:50,720
or find the solution to a problem after thinking long and hard about it.

74
00:05:50,720 --> 00:05:56,879
If someone gives you a blank check, you have unlimited money and freedom to complete a task.

75
00:05:56,879 --> 00:06:02,240
When you describe something as laser-like, you mean that it's very accurate and precise.

76
00:06:02,240 --> 00:06:08,720
And finally, the adjective stark has several meanings, including obvious, harsh and plain.

77
00:06:08,720 --> 00:06:12,000
Once again, our six minutes are up. Bye for now. Bye-bye.

78
00:06:15,920 --> 00:06:17,920
ABC Learning English.

