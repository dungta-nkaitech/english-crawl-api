1
00:00:00,000 --> 00:00:03,120
This is a download from BBC Learning English.

2
00:00:03,120 --> 00:00:05,679
To find out more, visit our website.

3
00:00:05,679 --> 00:00:08,240
6M8English

4
00:00:08,240 --> 00:00:10,880
from BBCLearningEnglish.com

5
00:00:13,120 --> 00:00:17,760
Welcome to 6 Minute English, the programme where we explore an interesting topic

6
00:00:17,760 --> 00:00:20,960
and bring you six items of useful vocabulary.

7
00:00:20,960 --> 00:00:21,839
I'm Catherine.

8
00:00:21,839 --> 00:00:22,800
And I'm Rob.

9
00:00:22,800 --> 00:00:24,800
I have a question for you, Rob.

10
00:00:24,800 --> 00:00:29,359
How would you feel about having therapy from a robot?

11
00:00:29,359 --> 00:00:30,960
Oh, I'm not too sure about that.

12
00:00:30,960 --> 00:00:32,320
You'll need to tell me more.

13
00:00:32,320 --> 00:00:37,119
But first things first, the word therapy refers to a kind of treatment

14
00:00:37,119 --> 00:00:39,039
that helps someone feel better,

15
00:00:39,039 --> 00:00:41,439
including treatment for mental health issues.

16
00:00:41,439 --> 00:00:44,640
Someone who delivers therapy is called a therapist.

17
00:00:44,640 --> 00:00:48,719
We'll find out more about this robot therapist in just a moment.

18
00:00:48,719 --> 00:00:55,039
But first, Rob, I've got a question for you about the scale of mental health issues globally.

19
00:00:55,039 --> 00:01:03,519
So, roughly, how many people do you think experience mental health issues at some point during their lifetime?

20
00:01:03,519 --> 00:01:10,719
Is it a one in ten people, b one in four, or c one in three?

21
00:01:10,719 --> 00:01:15,599
I'll go for one in four, but I know whichever answer is right, it's a big issue.

22
00:01:15,599 --> 00:01:17,519
How might a robot therapist help?

23
00:01:17,519 --> 00:01:21,359
We're not talking about a robot in the Star Wars sense.

24
00:01:21,359 --> 00:01:24,319
So there's no flashing lights and mechanical arms, Rob.

25
00:01:24,399 --> 00:01:28,639
It's actually an app in your smartphone that talks to you,

26
00:01:28,639 --> 00:01:31,359
and it's called woebot.

27
00:01:31,359 --> 00:01:33,679
Ah, so it has a sense of humour.

28
00:01:33,679 --> 00:01:38,559
Woe means sadness, so this is a woebot, not a robot.

29
00:01:38,559 --> 00:01:45,199
And it was developed by psychologist Dr. Allison Darcy from Stanford University in the US.

30
00:01:45,199 --> 00:01:49,759
Here she is talking to the BBC Radio Programme all in the mind.

31
00:01:49,759 --> 00:01:53,679
Well, after you start an initial conversation with a robot and he'll take you through

32
00:01:53,680 --> 00:01:57,360
sort of what he can do and what he can't do, he'll just essentially check in with you every day

33
00:01:57,360 --> 00:02:00,720
and just give you a sort of figurative tap on the shoulder and say,

34
00:02:00,720 --> 00:02:02,320
hey, Claudia, how are you doing?

35
00:02:02,320 --> 00:02:04,240
What's going on in your day? How do you feel?

36
00:02:04,240 --> 00:02:07,200
So if you say, like, I'm really, really stressed out,

37
00:02:07,200 --> 00:02:10,560
woebot might offer to help talk you through something.

38
00:02:11,920 --> 00:02:15,920
Woebot checks in with you every day and asks you how you are.

39
00:02:15,920 --> 00:02:20,960
So here, to check in with someone doesn't mean to register at a hotel with that person.

40
00:02:21,040 --> 00:02:26,240
It's an informal way of saying you talk to someone in order to report or find out information.

41
00:02:26,240 --> 00:02:29,520
And this usage is more common in the United States.

42
00:02:29,520 --> 00:02:34,159
So for example, I can't meet you today, Rob, but I'll check in with you tomorrow to see

43
00:02:34,159 --> 00:02:35,920
how the project's getting on.

44
00:02:35,920 --> 00:02:38,800
So this robot checks in with you every day.

45
00:02:38,800 --> 00:02:43,360
It tracks your mood and talks to you about your emotions using a technique called

46
00:02:43,360 --> 00:02:45,600
Cognitive Behavioral Therapy.

47
00:02:45,600 --> 00:02:50,319
Cognitive Behavioral Therapy is a common therapeutic technique

48
00:02:50,319 --> 00:02:54,560
that helps people deal with problems by changing the way they think.

49
00:02:54,560 --> 00:02:58,000
That all sounds great, but does woebot actually work?

50
00:02:58,000 --> 00:03:02,479
They've done some trials which show that it can be more effective than simply reading

51
00:03:02,479 --> 00:03:08,479
information about mental health, but they haven't compared woebot to a real therapist

52
00:03:08,479 --> 00:03:10,639
due to ethical concerns.

53
00:03:10,639 --> 00:03:15,519
Yes, it could be unethical to deny a real patient access to a human therapist

54
00:03:15,519 --> 00:03:17,199
for the sake of a trial.

55
00:03:17,199 --> 00:03:19,919
Ethical basically means morally right.

56
00:03:19,919 --> 00:03:22,639
And another concern is privacy.

57
00:03:22,639 --> 00:03:27,759
People who use apps like this are not protected by strong privacy laws.

58
00:03:27,759 --> 00:03:33,519
Despite these fears, digital therapy is booming and woebot is just one of an increasing number

59
00:03:33,519 --> 00:03:35,279
of electronic services.

60
00:03:35,279 --> 00:03:40,959
One reason for this could be using an app carries less stigma than maybe seeing a human therapist.

61
00:03:40,959 --> 00:03:45,679
And stigma refers to the negative associations that people have about something,

62
00:03:45,679 --> 00:03:48,719
especially when these associations are not fair.

63
00:03:49,280 --> 00:03:53,439
Even though mental health is now being talked about more openly than before,

64
00:03:54,159 --> 00:03:59,360
some people do still see mental health issues and therapy negatively.

65
00:03:59,360 --> 00:04:04,159
Whatever you think of robot therapy, Dr Darcy believes that in the modern world,

66
00:04:04,159 --> 00:04:09,360
people need to self-reflect more, which means thinking deeply about yourself in order to

67
00:04:09,360 --> 00:04:11,280
understand the reasons behind your feelings.

68
00:04:11,919 --> 00:04:15,759
The world that we live in right now is very noisy, particularly digitally.

69
00:04:16,159 --> 00:04:21,279
Since we've had these little computers in our pockets with us everywhere we go,

70
00:04:21,279 --> 00:04:25,519
there aren't that many opportunities for real silence or self-reflection.

71
00:04:25,519 --> 00:04:30,959
Even a commute on the tube might have been a moment to just take a second to yourself,

72
00:04:30,959 --> 00:04:36,319
but now that void can be filled always with super-engaging content by looking at your phone.

73
00:04:36,959 --> 00:04:40,560
Darcy believes that we don't have much time for self-reflection,

74
00:04:40,560 --> 00:04:45,039
because there are so many distractions in life, especially smartphones.

75
00:04:45,120 --> 00:04:49,360
After discussing all this, would you actually try a therapy app like this?

76
00:04:49,360 --> 00:04:52,080
Yes, I would, actually. I think it might be quite helpful.

77
00:04:52,080 --> 00:04:54,879
And how about the question you asked me at the beginning of the programme?

78
00:04:54,879 --> 00:04:58,080
How many people experience mental health issues?

79
00:04:58,080 --> 00:05:04,879
The answer was one in four, according to the World Health Organization and the World Federation for Mental Health.

80
00:05:05,439 --> 00:05:12,000
But the WHO say that as many as two-thirds of people never seek help from a health professional

81
00:05:12,079 --> 00:05:15,279
with stigma being one of the main reasons.

82
00:05:15,279 --> 00:05:20,240
And just there we had the word stigma again. Let's now run through the other words we learned today.

83
00:05:20,240 --> 00:05:26,959
So we had WHO, meaning sadness. I'm full of WHO, WHO is me!

84
00:05:26,959 --> 00:05:32,319
Maybe you need some therapy. That's the process of receiving treatment for a particular health issue,

85
00:05:32,319 --> 00:05:34,079
especially mental health illness.

86
00:05:34,079 --> 00:05:40,000
And we had to check in with someone. After we finished this programme I need to check in with the boss

87
00:05:40,000 --> 00:05:41,519
about my new project.

88
00:05:41,519 --> 00:05:45,920
We also had self-reflection. That's the process of thinking deeply about yourself.

89
00:05:46,800 --> 00:05:53,519
And finally we had ethical. If you describe something as ethical, you mean it's morally right.

90
00:05:53,519 --> 00:05:59,600
So, WHO, stigma, therapy, check in with self-reflection and ethical.

91
00:05:59,600 --> 00:06:03,759
That's it for this edition of Six Minute English. We'll leave you to self-reflect.

92
00:06:03,759 --> 00:06:08,480
And after you've done that, do visit our Facebook, Twitter, Instagram and YouTube pages.

93
00:06:08,480 --> 00:06:11,200
And of course our website. Bye for now. Bye bye.

